{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLJhsA31aPTIP80aTY85xM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IreneCalle/Langchain__OpenAI_Pinecone_paso_a_paso_2024/blob/main/Langchain_%7C%7C_OpenAI_%7C%7C_Pinecone_paso_a_paso_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain + OpenAI + Pinecone**\n",
        "\n",
        "‚úÖ En este cuaderno, vamos a instalar langchain y Pinecone y configurar un\n",
        "\n",
        "entorno de desarrollo con .env.\n",
        "\n",
        "‚úÖ Cubre los conceptos b√°sicos de cadenas, prompts, plantillas y agentes.\n",
        "\n",
        "‚úÖ Luego pasamos a embeddings y los vectores, y c√≥mo se guardan en √≠ndices.\n",
        "\n",
        "‚úÖTratamos Pinecone y c√≥mo se gestionan los √≠ndices.\n",
        "\n",
        "‚úÖ Finalmente, combinamos todo para crear la base de una aplicaci√≥n.\n",
        "\n",
        "\n",
        "‚ùóPara que este cuaderno funcione necesitas completarlo con tus propias claves de OpenAI y Pinecone. No ejecutes todas las celdas sin haber configurado tus cuentas. (instrucciones en el cuaderno)"
      ],
      "metadata": {
        "id": "j2DvIZoJyw3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain primeros pasos** ü¶ú\n",
        "\n",
        "LangChain es un marco de orquestaci√≥n de c√≥digo abierto para el desarrollo de aplicaciones que utilizan modelos de lenguaje de gran tama√±o (IBM). Es una especie de herramienta intermedia y entorno que te permite construir aplicaciones que usan, por ejemplo, OpenAI: un chatbot, un procesador de textos, o un asistente de Marketing.\n",
        "\n",
        "Estos son los pasos para crear un entorno con un cuaderno de Google Colabü™ê\n",
        "y empezar a usar langchain ‚õìÔ∏èü¶ú\n",
        "\n",
        "Muchas de las ideas est√°n extra√≠das de materiales del ingeniero de software Andrei Dumitrescu, (definitivamene recomiendo sus cursos), y de los art√≠culos de\n",
        "PrinceKrampah, claros y directos ü™Ñ\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R3dHRnemYHbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Creaci√≥n de el entorno**"
      ],
      "metadata": {
        "id": "4UAbirBiZ3T5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar instalaremos las bibliotecas b√°sicas que utilizaremos."
      ],
      "metadata": {
        "id": "Vyl0B9KcYXqb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHuIZgwhTMSA",
        "outputId": "30ff31a5-e4e2-42a3-d744-e45cfba1c686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting langchain\n",
            "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain)\n",
            "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain)\n",
            "  Downloading langchain_core-0.1.10-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.77 (from langchain)\n",
            "  Downloading langsmith-0.0.80-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.0.12-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.10-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.0.80-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.0 langchain-community-0.0.12 langchain-core-0.1.10 langsmith-0.0.80 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
            "Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai\n",
            "  Downloading openai-1.7.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.2 typing-extensions-4.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting langchain_openai\n",
            "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.10)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.23.5)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.7.2)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.5.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (0.0.80)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai) (2023.6.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.7->langchain_openai) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain_openai) (2.0.7)\n",
            "Downloading langchain_openai-0.0.2.post1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.0.2.post1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting python-decouple\n",
            "  Downloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: python-decouple\n",
            "Successfully installed python-decouple-3.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m165.7/165.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Bibliotecas b√°sicas\n",
        "!pip install --upgrade pip\n",
        "!pip install python-dotenv\n",
        "!pip install langchain\n",
        "!pip install tiktoken\n",
        "!pip install pinecone-client\n",
        "!pip install openai\n",
        "!pip install langchain_openai\n",
        "!pip install python-decouple\n",
        "!pip install langchain_experimental -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Archivo .env y variables de entorno**\n",
        "\n",
        "* **dotenv** es una librer√≠a en Python que permite cargar variables de entorno desde un archivo denominado .env en una aplicaci√≥n.\n",
        "\n",
        "* En el archivo .env incluiremos las claves de las APIs a las que tenemos que\n",
        "conectarnos como variables de nuestro entorno.\n",
        "\n",
        "* Crea una cuenta en [Pinecone](https://app.pinecone.io/?sessionType=login) y [OpenAI](https://platform.openai.com/login) y en la secci√≥n de claves API de cada una genera una nueva clave (Generate API Key) desde cada una de tus cuentas en ambos sitios.\n",
        "\n",
        "* Copia las claves secretas de openAI y Pinecone y el nombre del entorno de pinecone y p√©galas en la variable env_content."
      ],
      "metadata": {
        "id": "AA6HtRD6Ykqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la funcionalidad para leer las variables de entorno\n",
        "\n",
        "from dotenv import dotenv_values\n"
      ],
      "metadata": {
        "id": "-jdSu1xWTpww"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifica estos datos para usar tus propias claves de openAI y Pinecone y nombre del entorno generado en Pinecone (en la web aparece junto a la clave como \"environment\")\n",
        "\n",
        "env_content = '''\n",
        "OPENAI_API_KEY=\"AquiTuClave\"\n",
        "\n",
        "PINECONE_API_KEY=\"AquiTuClave\"\n",
        "\n",
        "PINECONE_ENV=\"AquiTuEntorno\"\n",
        "'''"
      ],
      "metadata": {
        "id": "8hbVS8vXTvFQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaci√≥n de archivo .env donde guardaremos nuestras variables\n",
        "with open('.env', 'w') as file:\n",
        "    file.write(env_content)"
      ],
      "metadata": {
        "id": "d5XhfcvKUS_u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobar la creaci√≥n del archivo listando el contenito del directorio actual\n",
        "!ls -la\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inb5BnLGUZXv",
        "outputId": "519cf082-676a-4912-b15c-d4fdf62adad4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Jan 14 16:33 .\n",
            "drwxr-xr-x 1 root root 4096 Jan 14 16:31 ..\n",
            "drwxr-xr-x 4 root root 4096 Jan 11 17:01 .config\n",
            "-rw-r--r-- 1 root root  155 Jan 14 16:33 .env\n",
            "drwxr-xr-x 1 root root 4096 Jan 11 17:02 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de los valores de las variables del entorno\n",
        "env_vars = dotenv_values(\".env\")\n"
      ],
      "metadata": {
        "id": "M2QyEqEXUupL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Librer√≠a para trabajar con funcionalidades del sistema operativo\n",
        "import os"
      ],
      "metadata": {
        "id": "L2SJjExKUymB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar funci√≥n de carga de las variables y b√∫squeda autom√°tica del archivo .env\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "FkJGiredVFvi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el dotenv (en este caso seleccionamos que lo encuentre por √©l mismo)\n",
        "load_dotenv(find_dotenv(), override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icYhU2qqVP0l",
        "outputId": "c2eb41d9-fd48-474c-aab9-5742990183a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Probar que funciona pidi√©ndole una clave\n",
        "os.environ.get(\"OPENAI_API_KE\")"
      ],
      "metadata": {
        "id": "vFRJTc_6VZQ2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Otra forma de exportar claves sin dotenv es la siguiente:\n",
        "!export OPENAI_API_KEY=\"AquiTuCLave\"\n"
      ],
      "metadata": {
        "id": "Or591Oe5_qIp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con eso ya tenemos un entorno completo en el que comenzar a experimentar.üí°"
      ],
      "metadata": {
        "id": "7rgSBjxQvPOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Conceptos b√°sicos de GPT-3.5 & langchain**"
      ],
      "metadata": {
        "id": "px0MqrH1Z05Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las \"**conversaciones**\" en el contexto de un chatmodel como ChatGPT 3.5 se refieren a intercambios de mensajes entre un usuario y el modelo de IA. Estas conversaciones tienen entradas (inputs) y salidas (outputs) que representan los mensajes enviados y recibidos durante la interacci√≥n.\n",
        "\n",
        "Los **\"inputs\" son los mensajes o solicitudes** enviadas por el usuario al modelo. Pueden ser preguntas, comentarios, solicitudes de informaci√≥n o cualquier tipo de texto que el usuario desee comunicar al sistema.\n",
        "\n",
        "Los **\"outputs\" son las respuestas** generadas por el modelo en respuesta a los inputs.\n",
        "\n",
        "#### Mensajes\n",
        "OpenAI emplea una lista de diccionarios llamados mensajes. Los diccionarios definen 3 roles: system, user y assistant.\n",
        "- **System role:** Permite especificar la forma en que el modelo responde preguntas. Ejemplo cl√°sico: \"Eres un asistente √∫til y experto en derecho\".\n",
        "\n",
        "- **User role:** Equivalente a las consultas realizadas por el usuario.\n",
        "\n",
        "- **Assistant role:** Son las respuestas del modelo (basadas en los mensajes del usuario)."
      ],
      "metadata": {
        "id": "Jlkts95kdoJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, importamos un esquema para la estructura llamado \"messages\"\n",
        "from langchain.schema import(\n",
        "\n",
        "AIMessage,\n",
        "HumanMessage,\n",
        "SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "AlCYj06Zc4c8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Primera consulta** ‚ö°\n",
        "\n",
        "Ya estamos listos para seleccionar un modelo de IA y realizar nuestra primera consulta.\n",
        "\n",
        "**Par√°metros:**\n",
        "\n",
        "-**Temperatura** (Temperature):\n",
        "\n",
        "La temperatura es un par√°metro que afecta la aleatoriedad. Con un valor bajo el modelo tiende a elegir las opciones m√°s probables. Con un valor m√°s alto es m√°s creativo.\n",
        "\n",
        "-**Max Tokens**\n",
        "Controla la longitud m√°xima del texto generado.\n",
        "\n",
        "\n",
        "*-**NOTA**: a fecha de enero 2024 OpenAI est√° actualizando sus tarifas y es posible que el servicio de consultas no sea gratuito. Puedes cargar una cantidad nominal de 2-3 euros en la app para poder ejecutar consultas. Desactiva la opci√≥n de recarga autom√°tica para evitar incurrir en m√°s costes.*"
      ],
      "metadata": {
        "id": "LfGrC_3urjLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aunque no es una pr√°ctica ideal, he suprimido los warnings a efectos de focalizar en langchain\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', module='langchain')"
      ],
      "metadata": {
        "id": "yi1ua4zh4QN1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "n1va2-mZgD_q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionamos el modelo que queremos, determinamos con system c√≥mo debe comportarse el asistente, solicitamos su respuesta con el mensaje humano\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=1024)\n",
        "\n",
        "\n",
        "messages = [\n",
        "SystemMessage(content= \"you are a scientist and respond only in German\"),\n",
        "HumanMessage(content= \"explain relativity in one sentence\")\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "output = chat(messages)"
      ],
      "metadata": {
        "id": "YuDRaN_1gN_h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimimos la respuesta, y vemos que responde exactamente seg√∫n lo requerido por los mensajes\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezOV2X5OrdyR",
        "outputId": "30afc05f-b90d-4a2b-db08-3e51fd489317"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Die Relativit√§tstheorie besagt, dass Raum und Zeit nicht absolut sind, sondern von der Bewegung und der Gravitation abh√§ngen.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prompt templates** ‚ö°\n"
      ],
      "metadata": {
        "id": "kbUFHOu5vhmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El t√©rmino prompt se refiere al input que damos al modelo.\n",
        "Las templates o plantillas son una forma de crear promtps din√°micas que sean m√°s sencillas y flexibles. En una plantilla existe un texto base en el que el usuario introduce el valor de su input.\n",
        "\n",
        "Son una forma de reproducir un prompt con variaciones.\n",
        "\n",
        "Se ve mucho mejor con un ejemplo ‚¨áÔ∏è"
      ],
      "metadata": {
        "id": "DMrlHJwxvpoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain_openai import ChatOpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from decouple import config\n",
        "from langchain import PromptTemplate\n"
      ],
      "metadata": {
        "id": "xDthcHE64nPI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar creamos una plantilla de prompt, e introducimos entre corchetes las variables, que pueden hacer referencia tanto al contenido como al modo de presentaci√≥n de este. Por ejemplo, el tema que queremos tratar, el n√∫mero de l√≠neas que queremos en la respuesta, el idioma de respuesta."
      ],
      "metadata": {
        "id": "0b_CD9BwD6mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI()\n",
        "\n",
        "# creaci√≥n del prompt\n",
        "\n",
        "prompt_template: str = \"\"\"/\n",
        "You are a pathologist expert, give 3 interesting facts about the following disease: {disease}. Do not use technical words, give easy /\n",
        "to understand and short responses. Answer in {language}\n",
        "\"\"\"\n",
        "\n",
        "# Objeto prompt template\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)"
      ],
      "metadata": {
        "id": "lchB0sKu9gVV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despu√©s se formatea a str la plantilla, con los valores que queremos insertar en ella.\n",
        "\n",
        "Cuando lo tenemos instanciamos a openAI y generamos una predicci√≥n."
      ],
      "metadata": {
        "id": "AYbDeHktEQ3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# formateamos las respuestas que queremos\n",
        "prompt_formatted_str: str = prompt.format(\n",
        "    disease=\"HIV\", language= \"French\")\n",
        "\n",
        "# Se instancia OPENAI con la clave que hemos guardado\n",
        "llm = OpenAI(openai_api_key=config(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Se genera una predicci√≥n\n",
        "prediction = llm.predict(prompt_formatted_str)\n"
      ],
      "metadata": {
        "id": "GisyTtd8A7Ft"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos a imprimir nuestra prediccion\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd6vcfFlCciT",
        "outputId": "ba54cdb4-a5e9-4601-a064-ffbb96a85884"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Le VIH est un virus qui attaque le syst√®me immunitaire du corps, le rendant plus vuln√©rable aux maladies et infections.\n",
            "2. Bien qu'il n'existe pas encore de rem√®de pour le VIH, des m√©dicaments appel√©s antir√©troviraux peuvent aider √† contr√¥ler la maladie et √† r√©duire les risques de transmission.\n",
            "3. Le VIH peut √™tre transmis par le sang, les relations sexuelles non prot√©g√©es et de la m√®re √† l'enfant pendant la grossesse, l'accouchement ou l'allaitement. Il est important d'utiliser des pr√©cautions pour se prot√©ger et prot√©ger les autres du VIH.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos con otras variables para obtener otra respuesta\n",
        "prompt_formatted_str: str = prompt.format(\n",
        "    disease=\"Common cold\", language= \"Galizian\")\n",
        "\n",
        "prediction = llm.predict(prompt_formatted_str)\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bw3jzNsCx1j",
        "outputId": "ca429da3-de7f-490d-aba8-2314d811736c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. O resfriado com√∫n √© unha enfermidade moi com√∫n que afecta as v√≠as respiratorias superiores, como o nariz, garganta e pulm√≥ns.\n",
            "2. A pesar de ser chamado \"resfriado\", esta enfermidade non est√° relacionada co fr√≠o ou a humidade, sen√≥n que √© causada principalmente por virus que se propagan de persoa a persoa.\n",
            "3. A√≠nda que non hai cura para o resfriado com√∫n, pode ser tratado con medicamentos que alivian os s√≠ntomas como a congesti√≥n nasal, a tose e a dor de cabeza. O descanso e a hidrataci√≥n tam√©n son importantes para recuperarse.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cadenas simples** ‚õìÔ∏è"
      ],
      "metadata": {
        "id": "71kNwwqfHgKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalmente, en una aplicaci√≥n el LLM por s√≠ solo no basta. Las cadenas permiten combinar varios elementos para crear una aplicaci√≥n completa. Por ejemplo, podemos crear una aplicaci√≥n que recibe el input del usuario, lo transforma, y luego env√≠a el resultado de esa transformaci√≥n a el LLM para que pueda procesarlo .\n",
        "\n",
        "Langchain ofrece una implementaci√≥n est√°ndar para estas cadenas que hace que su uso sea m√°s sencillo. En el primer ejemplo, solo contamos con un elemento.\n",
        "\n"
      ],
      "metadata": {
        "id": "SZ_vbBnhIQtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "llm = OpenAI(openai_api_key=config(\"OPENAI_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "Rnhfc7cqPUCi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaci√≥n del LLM\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
        "\n",
        "# Plantilla\n",
        "template = '''You are an a history teacher.\n",
        "Write a few sentences about the following time of history {time} in {language}.'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['time', 'language'],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "output = chain.run({'time': 'Middle Ages', 'language': 'french'})\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAjNB36Nd2pX",
        "outputId": "231619dd-1b0a-4591-de17-dea8d0bb29f2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les Moyen √Çge, √©galement connus sous le nom de l'√©poque m√©di√©vale, √©taient une p√©riode de l'histoire europ√©enne qui s'√©tendait du 5√®me au 15√®me si√®cle. C'√©tait une p√©riode marqu√©e par l'effondrement de l'Empire romain et l'√©mergence de nouveaux royaumes et seigneuries f√©odales. Les Moyen √Çge √©taient caract√©ris√©s par une soci√©t√© hi√©rarchis√©e, o√π les chevaliers, les seigneurs et les paysans jouaient des r√¥les importants. Cette p√©riode a √©galement √©t√© marqu√©e par des √©v√©nements tels que les Croisades, la peste noire et la construction de magnifiques cath√©drales gothiques.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otro ejemplo con variable de edad."
      ],
      "metadata": {
        "id": "mDI1uvyMgFai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1.5)\n",
        "\n",
        "template = \"\"\" You are a {age} year-old that loves {hobby}, write a few sentences of why you like it. Answer in Spanish \"\"\"\n",
        "\n",
        "prompt= PromptTemplate(\n",
        "    input_variables=['age', 'hobby'],\n",
        "    template= template\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "output = chain.run({'age': '11', 'hobby': 'swimming'})\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP9Vn6C8e7Fp",
        "outputId": "857ace95-6fc5-4587-cad9-fb362bff7fee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Me gusta mucho nadar porque es una forma divertida de ejercitarme. Durante el verano, disfruto pasar d√≠as enteros en la piscina jugando con mis amigos y sumergi√©ndome bajo el agua. Nadar tambi√©n me relaja y me hace sentir libre y en paz. Adem√°s, me encanta aprender diferentes estilos de nataci√≥n y superar nuevos desaf√≠os en el agua.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cadenas secuenciales simples** ‚õìÔ∏è\n",
        "\n"
      ],
      "metadata": {
        "id": "px8IuxvLPEIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En las cadenas secuenciales, el output de un prompt se utiliza como input del siguiente."
      ],
      "metadata": {
        "id": "Irl_ppTyMEJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# Creaci√≥n de las instancia llm\n",
        "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
        "\n",
        "# Primer prompt: pedimos que defina un concepto\n",
        "prompt1 = PromptTemplate(\n",
        "    input_variables=['concept'],\n",
        "    template='''You are an experienced philosopher, explain in two lines the concept of {concept}, answer in Spanish.'''\n",
        ")\n",
        "\n",
        "\n",
        "# Cadena 1\n",
        "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
        "\n",
        "\n",
        "# Pedimos que ampl√≠e la definici√≥n del prompt1 con definiciones de otros autores\n",
        "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
        "prompt2 = PromptTemplate(\n",
        "    input_variables=['definition'],\n",
        "    template='Given the definition {definition}, provide the philosophical approach to it of 2 different philosophers in 2 lines, would they agree with the definition given?. Answer in Spanish'\n",
        ")\n",
        "\n",
        "\n",
        "# Cadena 2\n",
        "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
        "\n",
        "\n",
        "# Cadena final secuencial en orden\n",
        "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
        "\n",
        "# Ejecutamos un ejemplo\n",
        "output = overall_chain.run('evil')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayZ_q6DXHmGP",
        "outputId": "27560b67-a1d3-4a83-e5d9-31a7c54430b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mEl concepto de mal se refiere a la manifestaci√≥n de acciones o intenciones que causan da√±o o sufrimiento innecesario a otros seres conscientes, violando principios √©ticos y morales fundamentales.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m1) Para Immanuel Kant, el concepto de mal est√° relacionado con el incumplimiento de los principios √©ticos universales y con la acci√≥n que trata a otros seres como meros medios para un fin, por lo que estar√≠a de acuerdo con la definici√≥n dada.\n",
            "\n",
            "2) Seg√∫n Friedrich Nietzsche, el concepto de mal es una cuesti√≥n relativa y subjetiva, dependiendo de la perspectiva y los valores individualistas, por lo que podr√≠a cuestionar la definici√≥n dada.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqu√≠ el ejemplo de una app que pide un concepto filos√≥fico y te aporta una definici√≥n y la visi√≥n de dos autores."
      ],
      "metadata": {
        "id": "jU4qIno8NA0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n que pide un concepto al usuario por pantalla y devuelve la impresi√≥n de la variable output\n",
        "def get_user_input_and_run_chain():\n",
        "    concept = input(\"Ingrese un concepto de filosof√≠a: \")\n",
        "    output = overall_chain.run(concept)\n",
        "    print(f\"Resultado: {output}\")\n",
        "\n",
        "# Ejecutamos la funci√≥n\n",
        "\"\"\"\n",
        "get_user_input_and_run_chain()\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mYEx4ayxMCVa",
        "outputId": "0ad5ffba-a3fc-400d-a556-176f390dd3e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nget_user_input_and_run_chain()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langchain agents** ü¶æ"
      ],
      "metadata": {
        "id": "5q588EJijM-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los LLM son muy eficientes en algunas tareas, pero pueden dar respuestas terribles en algunas otras como l√≥gica, c√°lculo, o informaci√≥n reciente. Por ejemplo, a d√≠a de hoy, si le preguntas a ChatGPT una operaci√≥n matem√°tica con exponentes o por una respuesta sobre langchain agents probablemente te proporcione respuestas incorrecta.\n",
        "\n",
        "Los agentes de langchain permiten acceder a las herramientas necesarias para poder hacer tareas como calcular o acceder a informaci√≥n actualizada.\n"
      ],
      "metadata": {
        "id": "SvMY1GiHjgvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo**\n",
        "En este caso, en lugar de que el modelo nos genere la respuesta a un c√°lculo directamente, vamos a hacer que genere el c√≥digo de Python y luego lo ejecute para que nos de una respuesta correcta ‚ú®"
      ],
      "metadata": {
        "id": "nhbaAMBBl0cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "ABKuYKwemO7w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Agente para ejecutar c√≥digo Python. Los tools son funciones que los agentes emplean para interactuar con el mundo exterior\n",
        "agent_executor = create_python_agent(\n",
        "    llm=llm,\n",
        "    tool= PythonREPLTool(),\n",
        "    verbose=True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "qB0TrzahnQNT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Le pasamos nuestra consulta en lenguaje natural\n",
        "\n",
        "\n",
        "agent_executor.run(\"calcula el factorial de 13  y despues calcula la raiz cuadrada del resultado  y nuestralo con dos decimales\")\n",
        "agent_executor.run(\"5.1**7.3\")\n"
      ],
      "metadata": {
        "id": "RgwDQ7M1pXH8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "ffa693fd-0fb7-487c-ec0a-a3e88205ddea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m To calculate the factorial of 13, we can use a for loop to multiply all numbers from 1 to 13. To calculate the square root, we can use the math module.\n",
            "Action: Python_REPL\n",
            "Action Input: import math\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now that we have imported the math module, we can use the sqrt function to calculate the square root.\n",
            "Action: Python_REPL\n",
            "Action Input: math.sqrt(13*12*11*10*9*8*7*6*5*4*3*2*1)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m We can use string formatting to display the result with two decimal places.\n",
            "Action: Python_REPL\n",
            "Action Input: print(\"{:.2f}\".format(math.sqrt(13*12*11*10*9*8*7*6*5*4*3*2*1)))\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m78911.47\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 78911.47\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I can use the power operator to raise 5.1 to the power of 7.3\n",
            "Action: Python_REPL\n",
            "Action Input: 5.1**7.3\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can see that the result is a float\n",
            "Action: Python_REPL\n",
            "Action Input: type(5.1**7.3)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can see that the type is a float\n",
            "Action: Python_REPL\n",
            "Action Input: print(5.1**7.3)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 146306.05007233328\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'146306.05007233328'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Los embeddings üåü**"
      ],
      "metadata": {
        "id": "7nhOupgFvjdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Antes de seguir, conviene mencionar un concepto clave: los embeddings.\n",
        "\n",
        " Los embeddings son el n√∫cleo de construir aplicaciones de LMS.\n",
        "\n",
        "Las embeddings de texto son **representaciones num√©ricas del texto** y se utilizan en NLP y aprendizaje autom√°tico.\n",
        "\n",
        "Las embeddings de texto se pueden utilizar para medir la **relaci√≥n y similitud** entre dos fragmentos de texto.\n",
        "\n",
        "- La **relaci√≥n** es una medida de c√≥mo de estrechamente est√°n relacionados en significado dos fragmentos de texto.\n",
        "\n",
        "- En este contexto, la distancia entre dos embeddings o dos vectores mide su relaci√≥n, lo que se traduce en la relaci√≥n entre los conceptos de texto que representan.\n",
        "\n",
        "‚û°Ô∏è **Dos Embeddings o vectores similares representan conceptos similares.**\n",
        "\n",
        "Hay dos enfoques comunes para medir la relaci√≥n y similitud entre embeddings de texto: **Similitud coseno y distancia euclidiana.**\n",
        "\n",
        "Un ejemplo de c√≥mo se pueden utilizar las embeddings de texto para medir la relaci√≥n y similitud es la clasificaci√≥n de textos, la agrupaci√≥n de textos o el question-anwering."
      ],
      "metadata": {
        "id": "lVSkOOYSwLO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Bases de datos de vectores: Pinecone**"
      ],
      "metadata": {
        "id": "DqWw9Qsuxytn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Uno de los retos actuales de la IA es el **procesamiento eficiente** de los datos.\n",
        "\n",
        "- Las Vector Databases son bases de datos dise√±adas para almacenar y recuperar vectores num√©ricos, como **embeddings**.\n",
        "- Estas bases de datos permiten realizar **consultas eficientes** basadas en la similitud de los vectores.\n",
        "\n",
        "- Se usan para almacenar **datos no estructurados**.\n",
        "- Se usan en los chatbots, la traducci√≥n inform√°tica y tareas de aprendizaje autom√°tico.\n",
        "- En estos ejemplos empleamos Pinecone, que ofrece una infraestructura para almacenar y recuperar vectores similares, como embeddings (representaciones num√©ricas) de texto."
      ],
      "metadata": {
        "id": "VgUVjauHy2ZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Primeros pasos con Pinecone üåü**"
      ],
      "metadata": {
        "id": "MWHjcZcF1qG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos e iniciamos con las claves guardadas al inicio\n",
        "import pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.environ.get('PINECONE_API_KEY'),\n",
        "    environment= os.environ.get('PINECONE_ENV'))"
      ],
      "metadata": {
        "id": "Z8qj_ehYtBLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5ec38f-1534-40a7-effd-46950fc4d872"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.info.version()"
      ],
      "metadata": {
        "id": "-EGN69k_30vQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02bf333-759f-4e5d-a87a-468b417828bf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VersionResponse(server='2.0.11', client='2.2.4')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **√çndices en Pinecone**\n",
        "\n",
        "- Un √≠ndice es la unidad organizativa de **m√°s alto nivel** de datos vectoriales en Pinecone.\n",
        "\n",
        "- Acepta y almacena vectores, atiende consultas y realiza otras operaciones vectoriales\n",
        "\n",
        "- Cada √≠ndice se ejecuta en al menos una c√°psula (**pod**).\n",
        "\n",
        "- Las c√°psulas son unidades preconfiguradas de hardware para ejecutar un servicio de Pinecone.\n",
        "\n"
      ],
      "metadata": {
        "id": "4qALOS264T8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# listamos los √≠ndices y no hay nada\n",
        "pinecone.list_indexes()\n"
      ],
      "metadata": {
        "id": "o4n1u_KQ4DMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33fb16bd-03b3-43c9-bc66-c2a7c34e4aad"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['langchain-pinecone']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = 'langchain-pinecone'\n",
        "\n",
        "\n",
        "# Creamos el √≠ndice si no existe. 1536 es la dimension de los embeddings de OpenAI\n",
        "# El plan gratuito solo nos permite 1 pod\n",
        "if index_name not in pinecone.list_indexes():\n",
        "  print(f'Creando √≠ndice con el nombre {index_name}..........')\n",
        "  pinecone.create_index(index_name, dimension=1536, metric='cosine', pods=1, pod_type='p1.x2')\n",
        "  print(\"Preparado :)\")\n",
        "else:\n",
        "    print(f'El indice  {index_name} ya existe.')\n",
        "\n",
        "# Cuando termines puedes comprobar que est√° en tu cuenta de pinecone, en la secci√≥n \"indexes\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uguRjyeH43gc",
        "outputId": "a0ca7f44-f8c5-4641-add6-a8957f1ed70c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El indice  langchain-pinecone ya existe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Consultar √≠ndice**: pinecone.describe_index(index_name)\n",
        "* **Borrar √≠ndice**: pinecone.delete_index(index_name)\n",
        "* **Estad√≠sticas**: index.describe_index_stats()"
      ],
      "metadata": {
        "id": "pAVWOuAD6hq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consultamos las estad√≠sticas del √≠nidce\n",
        "index = pinecone.Index(index_name)\n",
        "index.describe_index_stats()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qm0A3IU16vZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0feee922-b4d7-4439-9a85-f619ce9b26e5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.00605,\n",
              " 'namespaces': {'': {'vector_count': 605}},\n",
              " 'total_vector_count': 605}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Consultas de similaridad**\n",
        "\n",
        " A continuaci√≥n hay un ejemplo b√°sico de b√∫squeda y recuperaci√≥n de informaci√≥n basada en similitud de vectores. Este tipo de enfoque se utiliza en diversas aplicaciones, como sistemas de recomendaci√≥n, b√∫squeda de im√°genes similares, recuperaci√≥n de documentos. En este caso, en lugar de trabajar con datos reales, vamos a generar vectores aleatorios, y compararlos con un vector de consulta, tambi√©n aleatorio.\n",
        "\n",
        "  **Generar vectores ‚ÜóÔ∏è‚ÜóÔ∏è**\n",
        "\n",
        "\n",
        "Vamos a generar algunos vectores aleatorios para nuestro √≠ndice con la biblioteca random y list comprehension.\n",
        "Creamos una lista llamada vectors que contiene 1536 n√∫meros decimales aleatorios en el rango [0.0, 1.0) como necesitamos 5 vectores, hacemos esto 5 veces."
      ],
      "metadata": {
        "id": "iQOpv6XgnUA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "2PkgSj5wm_RG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar 5 vectores de 1536 n√∫meros 0-1\n",
        "vectors = [[random.random() for _ in range (1536)]for v in range (5)]\n",
        "\n"
      ],
      "metadata": {
        "id": "pFOV43MX73To"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista con cinco elementos que se corresponden con los ids de los vectores\n",
        "ids = list(\"abcde\")"
      ],
      "metadata": {
        "id": "2yGr6UMvsCX-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a conectar los ids que hemos creado y los vectores en una lista de tuplas. El m√©todo que usamos nos devolver√° el n√∫mero de vectores que hemos insertado, en este caso 5."
      ],
      "metadata": {
        "id": "VspXAIQKtKTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionamos el √≠ndice e insertamos los vectores en el √≠ndice con el m√©todo upsert\n",
        "\n",
        "index.upsert(vectors=zip(ids, vectors))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmBWH5mHsU5L",
        "outputId": "75114192-12b5-4619-ed64-c4d2b815b793"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algunas operaciones √∫tiles con vectores**\n",
        "* Upsert (inserci√≥n/actualizaci√≥n de vectores):\n",
        " - index.upsert(vectors=zip(ids, vectors))\n",
        " - index.upsert(vectors=[('c',[0.3]*1536)])\n",
        "* Selecci√≥n (fetch) :\n",
        " - index.fetch(ids=['c','d'])\n",
        "* Borrar:\n",
        " - index.delete(ids=['b','d'])\n",
        " *Si seleccionas un vector que no existe no te devolver√° error, sino un vector vac√≠o.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "relyem2fuI9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Queries (consulta)**\n",
        "\n",
        "Vamos a buscar los vectores m√°s similares a nuestro vector de consulta."
      ],
      "metadata": {
        "id": "bx8LXgthwRy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el vector de las queries\n",
        "\n",
        "vector_Q = [random.random() for _ in range(1536) for v in range (1)]\n",
        "\n",
        "# La query que hagamos devolver√° los ids con de los vectores m√°s similares con el namespace del √≠ndice junto con su similaridad.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mb34dxGZ8fps"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la query. Si revisas documentaci√≥n antigua, puede que encuentres el par√°metro 'query' en lugar de 'vector', pero ya est√° deprecado\n",
        "\n",
        "# Esto nos retornar√° los 3 vectores m√°s similares, junto con su puntuaci√≥n, en orden descendente\n",
        "\n",
        "index.query(\n",
        "    vector= vector_Q,\n",
        "    top_k=3,\n",
        "    include_values= False\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2MqIyAxG49",
        "outputId": "e7b1a1de-6c00-4a9c-ea64-59546be6cf54"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'id': 'b', 'score': 0.740012825, 'values': []},\n",
              "             {'id': 'c', 'score': 0.735981822, 'values': []},\n",
              "             {'id': '24e56d9c-2c83-4e77-b86b-a789392379ee',\n",
              "              'score': -0.0174417682,\n",
              "              'values': []}],\n",
              " 'namespace': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting y embedding de texto con langchain**üìå\n",
        "\n",
        "Cuando trabajamos con segmentos muy largos de texto, conviene segmentar estos en fragmentos m√°s peque√±os.\n",
        "A la vez que hacemos esto, debemos de tratar de preservar los textos relacionados sem√°nticamente dentro de la misma unidad a la hora de hacer la segmentaci√≥n."
      ],
      "metadata": {
        "id": "sL9j3UxEzTHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos el separador de texto\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "GmFggAg4e7ik"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùó Sube el archivo de churchill_speech a tu Drive antes de ejecutar esta celda."
      ],
      "metadata": {
        "id": "qesb2-gt1knx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subimos el archivo de texto\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta\n",
        "ruta_del_archivo = '/content/drive/MyDrive/churchill_speech.txt'\n",
        "\n",
        "# Lee el archivo de texto\n",
        "with open(ruta_del_archivo, 'r') as archivo:\n",
        "    churchill_speech = archivo.read()\n",
        "\n",
        "# Muestra el contenido\n",
        "print(churchill_speech)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uChaPkJhgOuc",
        "outputId": "60d3f794-688a-4011-cb06-6039dce4c131"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Winston Churchill Speech - We Shall Fight on the Beaches\n",
            "We Shall Fight on the Beaches\n",
            "June 4, 1940\n",
            "House of Commons\n",
            "From the moment that the French defenses at Sedan and on the Meuse were broken at the end of the\n",
            "second week of May, only a rapid retreat to Amiens and the south could have saved the British and\n",
            "French Armies who had entered Belgium at the appeal of the Belgian King; but this strategic fact was\n",
            "not immediately realized. The French High Command hoped they would be able to close the gap, and\n",
            "the Armies of the north were under their orders. Moreover, a retirement of this kind would have\n",
            "involved almost certainly the destruction of the fine Belgian Army of over 20 divisions and the\n",
            "abandonment of the whole of Belgium. Therefore, when the force and scope of the German\n",
            "penetration were realized and when a new French Generalissimo, General Weygand, assumed\n",
            "command in place of General Gamelin, an effort was made by the French and British Armies in\n",
            "Belgium to keep on holding the right hand of the Belgians and to give their own right hand to a newly\n",
            "created French Army which was to have advanced across the Somme in great strength to grasp it.\n",
            "However, the German eruption swept like a sharp scythe around the right and rear of the Armies of\n",
            "the north. Eight or nine armored divisions, each of about four hundred armored vehicles of different\n",
            "kinds, but carefully assorted to be complementary and divisible into small self-contained units, cut off\n",
            "all communications between us and the main French Armies. It severed our own communications for\n",
            "food and ammunition, which ran first to Amiens and afterwards through Abbeville, and it shore its\n",
            "way up the coast to Boulogne and Calais, and almost to Dunkirk. Behind this armored and\n",
            "mechanized onslaught came a number of German divisions in lorries, and behind them again there\n",
            "plodded comparatively slowly the dull brute mass of the ordinary German Army and German people,\n",
            "always so ready to be led to the trampling down in other lands of liberties and comforts which they\n",
            "have never known in their own.\n",
            "I have said this armored scythe-stroke almost reached Dunkirk-almost but not quite. Boulogne and\n",
            "Calais were the scenes of desperate fighting. The Guards defended Boulogne for a while and were\n",
            "then withdrawn by orders from this country. The Rifle Brigade, the 60th Rifles, and the Queen\n",
            "Victoria's Rifles, with a battalion of British tanks and 1,000 Frenchmen, in all about four thousand\n",
            "strong, defended Calais to the last. The British Brigadier was given an hour to surrender. He spurned\n",
            "the offer, and four days of intense street fighting passed before silence reigned over Calais, which\n",
            "marked the end of a memorable resistance. Only 30 unwounded survivors were brought off by the\n",
            "Navy, and we do not know the fate of their comrades. Their sacrifice, however, was not in vain. At\n",
            "least two armored divisions, which otherwise would have been turned against the British\n",
            "Expeditionary Force, had to be sent to overcome them. They have added another page to the glories\n",
            "of the light divisions, and the time gained enabled the Graveline water lines to be flooded and to be\n",
            "held by the French troops.\n",
            "Thus it was that the port of Dunkirk was kept open. When it was found impossible for the Armies of\n",
            "the north to reopen their communications to Amiens with the main French Armies, only one choice\n",
            "remained. It seemed, indeed, forlorn. The Belgian, British and French Armies were almost\n",
            "surrounded. Their sole line of retreat was to a single port and to its neighboring beaches. They were\n",
            "pressed on every side by heavy attacks and far outnumbered in the air.\n",
            "When, a week ago today, I asked the House to fix this afternoon as the occasion for a statement, I\n",
            "feared it would be my hard lot to announce the greatest military disaster in our long history. I\n",
            "thought-and some good judges agreed with me-that perhaps 20,000 or 30,000 men might be reembarked. But it certainly seemed that the whole of the French First Army and the whole of the\n",
            "British Expeditionary Force north of the Amiens-Abbeville gap would be broken up in the open field\n",
            "or else would have to capitulate for lack of food and ammunition. These were the hard and heavy\n",
            "tidings for which I called upon the House and the nation to prepare themselves a week ago. The whole\n",
            "root and core and brain of the British Army, on which and around which we were to build, and are to\n",
            "build, the great British Armies in the later years of the war, seemed about to perish upon the field or\n",
            "to be led into an ignominious and starving captivity.\n",
            "That was the prospect a week ago. But another blow which might well have proved final was yet to\n",
            "fall upon us. The King of the Belgians had called upon us to come to his aid. Had not this Ruler and\n",
            "his Government severed themselves from the Allies, who rescued their country from extinction in the\n",
            "late war, and had they not sought refuge in what was proved to be a fatal neutrality, the French and\n",
            "British Armies might well at the outset have saved not only Belgium but perhaps even Poland. Yet at\n",
            "the last moment, when Belgium was already invaded, King Leopold called upon us to come to his aid,\n",
            "and even at the last moment we came. He and his brave, efficient Army, nearly half a million strong,\n",
            "guarded our left flank and thus kept open our only line of retreat to the sea. Suddenly, without prior\n",
            "consultation, with the least possible notice, without the advice of his Ministers and upon his own\n",
            "personal act, he sent a plenipotentiary to the German Command, surrendered his Army, and exposed\n",
            "our whole flank and means of retreat.\n",
            "I asked the House a week ago to suspend its judgment because the facts were not clear, but I do not\n",
            "feel that any reason now exists why we should not form our own opinions upon this pitiful episode.\n",
            "The surrender of the Belgian Army compelled the British at the shortest notice to cover a flank to the\n",
            "sea more than 30 miles in length. Otherwise all would have been cut off, and all would have shared\n",
            "the fate to which King Leopold had condemned the finest Army his country had ever formed. So in\n",
            "doing this and in exposing this flank, as anyone who followed the operations on the map will see,\n",
            "contact was lost between the British and two out of the three corps forming the First French Army,\n",
            "who were still farther from the coast than we were, and it seemed impossible that any large number of\n",
            "Allied troops could reach the coast.\n",
            "The enemy attacked on all sides with great strength and fierceness, and their main power, the power\n",
            "of their far more numerous Air Force, was thrown into the battle or else concentrated upon Dunkirk\n",
            "and the beaches. Pressing in upon the narrow exit, both from the east and from the west, the enemy\n",
            "began to fire with cannon upon the beaches by which alone the shipping could approach or depart.\n",
            "They sowed magnetic mines in the channels and seas; they sent repeated waves of hostile aircraft,\n",
            "sometimes more than a hundred strong in one formation, to cast their bombs upon the single pier that\n",
            "remained, and upon the sand dunes upon which the troops had their eyes for shelter. Their U-boats,\n",
            "one of which was sunk, and their motor launches took their toll of the vast traffic which now began.\n",
            "For four or five days an intense struggle reigned. All their armored divisions-or what Was left of\n",
            "them-together with great masses of infantry and artillery, hurled themselves in vain upon the evernarrowing, ever-contracting appendix within which the British and French Armies fought.\n",
            "Meanwhile, the Royal Navy, with the willing help of countless merchant seamen, strained every nerve\n",
            "to embark the British and Allied troops; 220 light warships and 650 other vessels were engaged. They\n",
            "had to operate upon the difficult coast, often in adverse weather, under an almost ceaseless hail of\n",
            "bombs and an increasing concentration of artillery fire. Nor were the seas, as I have said, themselves\n",
            "free from mines and torpedoes. It was in conditions such as these that our men carried on, with little\n",
            "or no rest, for days and nights on end, making trip after trip across the dangerous waters, bringing\n",
            "with them always men whom they had rescued. The numbers they have brought back are the measure\n",
            "of their devotion and their courage. The hospital ships, which brought off many thousands of British\n",
            "and French wounded, being so plainly marked were a special target for Nazi bombs; but the men and\n",
            "women on board them never faltered in their duty.\n",
            "Meanwhile, the Royal Air Force, which had already been intervening in the battle, so far as its range\n",
            "would allow, from home bases, now used part of its main metropolitan fighter strength, and struck at\n",
            "the German bombers and at the fighters which in large numbers protected them. This struggle was\n",
            "protracted and fierce. Suddenly the scene has cleared, the crash and thunder has for the moment-but\n",
            "only for the moment-died away. A miracle of deliverance, achieved by valor, by perseverance, by\n",
            "perfect discipline, by faultless service, by resource, by skill, by unconquerable fidelity, is manifest to\n",
            "us all. The enemy was hurled back by the retreating British and French troops. He was so roughly\n",
            "handled that he did not hurry their departure seriously. The Royal Air Force engaged the main\n",
            "strength of the German Air Force, and inflicted upon them losses of at least four to one; and the\n",
            "Navy, using nearly 1,000 ships of all kinds, carried over 335,000 men, French and British, out of the\n",
            "jaws of death and shame, to their native land and to the tasks which lie immediately ahead. We must\n",
            "be very careful not to assign to this deliverance the attributes of a victory. Wars are not won by\n",
            "evacuations. But there was a victory inside this deliverance, which should be noted. It was gained by\n",
            "the Air Force. Many of our soldiers coming back have not seen the Air Force at work; they saw only\n",
            "the bombers which escaped its protective attack. They underrate its achievements. I have heard much\n",
            "talk of this; that is why I go out of my way to say this. I will tell you about it.\n",
            "This was a great trial of strength between the British and German Air Forces. Can you conceive a\n",
            "greater objective for the Germans in the air than to make evacuation from these beaches impossible,\n",
            "and to sink all these ships which were displayed, almost to the extent of thousands? Could there have\n",
            "been an objective of greater military importance and significance for the whole purpose of the war\n",
            "than this? They tried hard, and they were beaten back; they were frustrated in their task. We got the\n",
            "Army away; and they have paid fourfold for any losses which they have inflicted. Very large\n",
            "formations of German aeroplanes-and we know that they are a very brave race-have turned on\n",
            "several occasions from the attack of one-quarter of their number of the Royal Air Force, and have\n",
            "dispersed in different directions. Twelve aeroplanes have been hunted by two. One aeroplane was\n",
            "driven into the water and cast away by the mere charge of a British aeroplane, which had no more\n",
            "ammunition. All of our types-the Hurricane, the Spitfire and the new Defiant-and all our pilots have\n",
            "been vindicated as superior to what they have at present to face.\n",
            "When we consider how much greater would be our advantage in defending the air above this Island\n",
            "against an overseas attack, I must say that I find in these facts a sure basis upon which practical and\n",
            "reassuring thoughts may rest. I will pay my tribute to these young airmen. The great French Army\n",
            "was very largely, for the time being, cast back and disturbed by the onrush of a few thousands of\n",
            "armored vehicles. May it not also be that the cause of civilization itself will be defended by the skill\n",
            "and devotion of a few thousand airmen? There never has been, I suppose, in all the world, in all the\n",
            "history of war, such an opportunity for youth. The Knights of the Round Table, the Crusaders, all fall\n",
            "back into the past-not only distant but prosaic; these young men, going forth every morn to guard\n",
            "their native land and all that we stand for, holding in their hands these instruments of colossal and\n",
            "shattering power, of whom it may be said that\n",
            "Every morn brought forth a noble chance\n",
            "And every chance brought forth a noble knight,\n",
            "deserve our gratitude, as do all the brave men who, in so many ways and on so many occasions, are\n",
            "ready, and continue ready to give life and all for their native land.\n",
            "I return to the Army. In the long series of very fierce battles, now on this front, now on that, fighting\n",
            "on three fronts at once, battles fought by two or three divisions against an equal or somewhat larger\n",
            "number of the enemy, and fought fiercely on some of the old grounds that so many of us knew so wellin these battles our losses in men have exceeded 30,000 killed, wounded and missing. I take occasion\n",
            "to express the sympathy of the House to all who have suffered bereavement or who are still anxious.\n",
            "The President of the Board of Trade [Sir Andrew Duncan] is not here today. His son has been killed,\n",
            "and many in the House have felt the pangs of affliction in the sharpest form. But I will say this about\n",
            "the missing: We have had a large number of wounded come home safely to this country, but I would\n",
            "say about the missing that there may be very many reported missing who will come back home, some\n",
            "day, in one way or another. In the confusion of this fight it is inevitable that many have been left in\n",
            "positions where honor required no further resistance from them.\n",
            "Against this loss of over 30,000 men, we can set a far heavier loss certainly inflicted upon the enemy.\n",
            "But our losses in material are enormous. We have perhaps lost one-third of the men we lost in the\n",
            "opening days of the battle of 21st March, 1918, but we have lost nearly as many guns -- nearly one\n",
            "thousand-and all our transport, all the armored vehicles that were with the Army in the north. This\n",
            "loss will impose a further delay on the expansion of our military strength. That expansion had not\n",
            "been proceeding as far as we had hoped. The best of all we had to give had gone to the British\n",
            "Expeditionary Force, and although they had not the numbers of tanks and some articles of equipment\n",
            "which were desirable, they were a very well and finely equipped Army. They had the first-fruits of all\n",
            "that our industry had to give, and that is gone. And now here is this further delay. How long it will be,\n",
            "how long it will last, depends upon the exertions which we make in this Island. An effort the like of\n",
            "which has never been seen in our records is now being made. Work is proceeding everywhere, night\n",
            "and day, Sundays and week days. Capital and Labor have cast aside their interests, rights, and\n",
            "customs and put them into the common stock. Already the flow of munitions has leaped forward.\n",
            "There is no reason why we should not in a few months overtake the sudden and serious loss that has\n",
            "come upon us, without retarding the development of our general program.\n",
            "Nevertheless, our thankfulness at the escape of our Army and so many men, whose loved ones have\n",
            "passed through an agonizing week, must not blind us to the fact that what has happened in France\n",
            "and Belgium is a colossal military disaster. The French Army has been weakened, the Belgian Army\n",
            "has been lost, a large part of those fortified lines upon which so much faith had been reposed is gone,\n",
            "many valuable mining districts and factories have passed into the enemy's possession, the whole of the\n",
            "Channel ports are in his hands, with all the tragic consequences that follow from that, and we must\n",
            "expect another blow to be struck almost immediately at us or at France. We are told that Herr Hitler\n",
            "has a plan for invading the British Isles. This has often been thought of before. When Napoleon lay at\n",
            "Boulogne for a year with his flat-bottomed boats and his Grand Army, he was told by someone.\n",
            "\"There are bitter weeds in England.\" There are certainly a great many more of them since the British\n",
            "Expeditionary Force returned.\n",
            "The whole question of home defense against invasion is, of course, powerfully affected by the fact that\n",
            "we have for the time being in this Island incomparably more powerful military forces than we have\n",
            "ever had at any moment in this war or the last. But this will not continue. We shall not be content\n",
            "with a defensive war. We have our duty to our Ally. We have to reconstitute and build up the British\n",
            "Expeditionary Force once again, under its gallant Commander-in-Chief, Lord Gort. All this is in\n",
            "train; but in the interval we must put our defenses in this Island into such a high state of organization\n",
            "that the fewest possible numbers will be required to give effective security and that the largest\n",
            "possible potential of offensive effort may be realized. On this we are now engaged. It will be very\n",
            "convenient, if it be the desire of the House, to enter upon this subject in a secret Session. Not that the\n",
            "government would necessarily be able to reveal in very great detail military secrets, but we like to\n",
            "have our discussions free, without the restraint imposed by the fact that they will be read the next day\n",
            "by the enemy; and the Government would benefit by views freely expressed in all parts of the House\n",
            "by Members with their knowledge of so many different parts of the country. I understand that some\n",
            "request is to be made upon this subject, which will be readily acceded to by His Majesty's\n",
            "Government.\n",
            "We have found it necessary to take measures of increasing stringency, not only against enemy aliens\n",
            "and suspicious characters of other nationalities, but also against British subjects who may become a\n",
            "danger or a nuisance should the war be transported to the United Kingdom. I know there are a great\n",
            "many people affected by the orders which we have made who are the passionate enemies of Nazi\n",
            "Germany. I am very sorry for them, but we cannot, at the present time and under the present stress,\n",
            "draw all the distinctions which we should like to do. If parachute landings were attempted and fierce\n",
            "fighting attendant upon them followed, these unfortunate people would be far better out of the way,\n",
            "for their own sakes as well as for ours. There is, however, another class, for which I feel not the\n",
            "slightest sympathy. Parliament has given us the powers to put down Fifth Column activities with a\n",
            "strong hand, and we shall use those powers subject to the supervision and correction of the House,\n",
            "without the slightest hesitation until we are satisfied, and more than satisfied, that this malignancy in\n",
            "our midst has been effectively stamped out.\n",
            "Turning once again, and this time more generally, to the question of invasion, I would observe that\n",
            "there has never been a period in all these long centuries of which we boast when an absolute\n",
            "guarantee against invasion, still less against serious raids, could have been given to our people. In the\n",
            "days of Napoleon the same wind which would have carried his transports across the Channel might\n",
            "have driven away the blockading fleet. There was always the chance, and it is that chance which has\n",
            "excited and befooled the imaginations of many Continental tyrants. Many are the tales that are told.\n",
            "We are assured that novel methods will be adopted, and when we see the originality of malice, the\n",
            "ingenuity of aggression, which our enemy displays, we may certainly prepare ourselves for every kind\n",
            "of novel stratagem and every kind of brutal and treacherous maneuver. I think that no idea is so\n",
            "outlandish that it should not be considered and viewed with a searching, but at the same time, I hope,\n",
            "with a steady eye. We must never forget the solid assurances of sea power and those which belong to\n",
            "air power if it can be locally exercised.\n",
            "I have, myself, full confidence that if all do their duty, if nothing is neglected, and if the best\n",
            "arrangements are made, as they are being made, we shall prove ourselves once again able to defend\n",
            "our Island home, to ride out the storm of war, and to outlive the menace of tyranny, if necessary for\n",
            "years, if necessary alone. At any rate, that is what we are going to try to do. That is the resolve of His\n",
            "Majesty's Government-every man of them. That is the will of Parliament and the nation. The British\n",
            "Empire and the French Republic, linked together in their cause and in their need, will defend to the\n",
            "death their native soil, aiding each other like good comrades to the utmost of their strength. Even\n",
            "though large tracts of Europe and many old and famous States have fallen or may fall into the grip of\n",
            "the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the\n",
            "end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing\n",
            "confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we\n",
            "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the\n",
            "streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment\n",
            "believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the\n",
            "seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God's good time,\n",
            "the New World, with all its power and might, steps forth to the rescue and the liberation of the old.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el separador de textos. Size corresponde con el tama√±o de items, en un caso normal ser√≠an m√°s para cada chunk\n",
        "# Overlap define la cantidad de solapamiento (overlap) entre fragmentos consecutivos.\n",
        "# Length_function: funci√≥n que se utilizar√° para determinar la longitud del texto. En este caso, la funci√≥n incorporada len.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "-PuAJtZDiZOt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos los chunks con el objeto separador que hemos creado, y lo guardamos en la variable chunks\n",
        "chunks = text_splitter.create_documents([churchill_speech])"
      ],
      "metadata": {
        "id": "8gvRDW5sjqPW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos a imprimir un chunk por √≠ndice\n",
        "print(chunks[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "welOd5pvkTIo",
        "outputId": "a52bf554-2d53-480e-f05f-9919215380a3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='From the moment that the French defenses at Sedan and on the Meuse were broken at the end of the'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver solo el contenido\n",
        "print(chunks[11].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m36VHlNckaXn",
        "outputId": "d8e6ef86-221e-4156-e52c-969d2ec82184"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "command in place of General Gamelin, an effort was made by the French and British Armies in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver n√∫mero de segmentos\n",
        "print(f'Ahora mismo hay un total de {len(chunks)} chunks de texto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xauanLBdk3k8",
        "outputId": "9228ec69-6347-4f88-a27e-eb96df09dc4c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahora mismo hay un total de 300 chunks de texto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "####**Costes de los embeddings**\n"
      ],
      "metadata": {
        "id": "ZuCYvpyfmWof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La codificaci√≥n para generar embeddings no es gratuita, as√≠ que es conveniente contar con una funci√≥n que permita anticipar los costes.\n"
      ],
      "metadata": {
        "id": "3mOYITipn70U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n"
      ],
      "metadata": {
        "id": "3xH86gYmmIee"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_embedding_costs(texts):\n",
        "  enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
        "  total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
        "  print(f'Tokens totales = {total_tokens}')\n",
        "  print(f'Costes de los embeddings en USD = {total_tokens/1000*0.0004:.6f}')\n",
        "\n",
        "print_embedding_costs(chunks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcMTSkbjmj6e",
        "outputId": "871e6add-9fb4-4a43-da3c-152fb43afc88"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens totales = 4820\n",
            "Costes de los embeddings en USD = 0.001928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Generar los embeddings**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sI3V9daOvgdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> El siguiente paso que debemos tomar es importar e instanciar los embeddings de OpenAI"
      ],
      "metadata": {
        "id": "KdxgHiEyoI5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "jOX074SYoRLn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora transformamos el primer chunk en un vector. As√≠, hemos codificado el texto."
      ],
      "metadata": {
        "id": "fsjXAfqmueil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# El argumento debe ser un texto, le podr√≠amos pasar directamente un string, por ejemplo.\n",
        "vector = embedding.embed_query(chunks[0].page_content)\n",
        "vector\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_7WiiQEutog",
        "outputId": "58604c6f-843f-403d-b6e4-c8c5db27b6d5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.04454859252972275,\n",
              " -0.03779107625713776,\n",
              " -0.002879912206270699,\n",
              " -0.008045266214119192,\n",
              " 0.015746282084248255,\n",
              " 0.022516546299967938,\n",
              " -0.02843255862727964,\n",
              " -0.009734645282265439,\n",
              " 0.0010447052554574756,\n",
              " 0.007229264674373191,\n",
              " 0.007854016333454415,\n",
              " 0.032742067486658956,\n",
              " 0.007420515020699245,\n",
              " -0.011723648511527381,\n",
              " 0.006314450277188572,\n",
              " -0.005351823642668397,\n",
              " 0.013234526573466103,\n",
              " -0.0025308802194518626,\n",
              " 0.013502277151454833,\n",
              " -0.011003272377775045,\n",
              " -0.008140891620112858,\n",
              " -0.02685155477090687,\n",
              " 0.029554560162353798,\n",
              " -0.0037612576647914073,\n",
              " -0.01436927884564262,\n",
              " -0.01841103805835576,\n",
              " 0.010837522108669883,\n",
              " -0.01865328809346232,\n",
              " 0.0030615999654312587,\n",
              " -0.014356529039862813,\n",
              " 0.007114514559709814,\n",
              " -0.008568017564316847,\n",
              " -0.016536783081112085,\n",
              " 0.005144635573456307,\n",
              " -0.018296287943692383,\n",
              " -0.023880797870148653,\n",
              " -0.022465545214203596,\n",
              " -0.008727392930532107,\n",
              " 0.0226057968030717,\n",
              " -0.012743650669040521,\n",
              " 0.013629778003220573,\n",
              " 0.00470475982347251,\n",
              " 0.00875289254209172,\n",
              " 0.0029516310279353096,\n",
              " -0.027922557082861794,\n",
              " 0.022299795876420992,\n",
              " 0.020578542293825226,\n",
              " -0.009887644814268239,\n",
              " -0.0159630325077952,\n",
              " 0.044242589740426934,\n",
              " 0.013808278078105543,\n",
              " 0.019201539055219593,\n",
              " -0.018678787705021935,\n",
              " -0.03781657586869738,\n",
              " -0.016881035287747325,\n",
              " 0.009039768760072718,\n",
              " -0.021802544137782952,\n",
              " 0.01960954029075387,\n",
              " -0.006193325259635291,\n",
              " -0.02204479417288951,\n",
              " -0.004379633722490812,\n",
              " -0.009760144893825054,\n",
              " -0.011411273613309323,\n",
              " -0.011481398476420818,\n",
              " -0.001418440340220647,\n",
              " -0.009894019717158142,\n",
              " -0.03406806963950025,\n",
              " 0.033889568633292726,\n",
              " -0.0011538773300921869,\n",
              " 0.011092522880878806,\n",
              " 0.032104566021797926,\n",
              " 0.027310555229560378,\n",
              " 0.004408321716817934,\n",
              " 0.011551523339532315,\n",
              " 0.014688029578073136,\n",
              " -0.011328398013095464,\n",
              " -0.019737040211197054,\n",
              " -0.01702128501397032,\n",
              " 0.004083195615836237,\n",
              " 0.011902149517734904,\n",
              " 0.018538537978798945,\n",
              " -0.017123285322853888,\n",
              " 0.0010311583539857915,\n",
              " 0.010576146433571056,\n",
              " 0.030013560621007306,\n",
              " 0.005335885919782361,\n",
              " 0.008453267449653471,\n",
              " 0.02664755415313973,\n",
              " 0.0028384746389944087,\n",
              " -0.022937297341282022,\n",
              " -0.010136270683587259,\n",
              " -0.00020320353662717732,\n",
              " 0.005135072753460174,\n",
              " 0.004902385072688468,\n",
              " -0.012673525805929025,\n",
              " 0.02096104205515478,\n",
              " -0.015644281775364685,\n",
              " 0.02654555384425616,\n",
              " 0.017199784157532733,\n",
              " -0.02470955014699702,\n",
              " 0.027132056085997964,\n",
              " 0.005409198700000086,\n",
              " -0.0150705312020478,\n",
              " -0.007713765675908869,\n",
              " -0.011290147664433488,\n",
              " -0.0012789870111976156,\n",
              " -0.014280029273861412,\n",
              " -0.0075416405039138035,\n",
              " -0.006508888074959578,\n",
              " -0.00670013888694691,\n",
              " -0.014688029578073136,\n",
              " 0.010945897320443355,\n",
              " 0.014165279159198036,\n",
              " -0.03855607950508709,\n",
              " 0.0007387046198450654,\n",
              " -0.0427125869698185,\n",
              " -0.004319071213714172,\n",
              " -0.013036901789911423,\n",
              " 0.014356529039862813,\n",
              " -0.03564907163322791,\n",
              " 0.010620771685122937,\n",
              " -0.0014630654753572086,\n",
              " 0.017646036673051542,\n",
              " -0.005221135805118984,\n",
              " 0.0033532568949184065,\n",
              " 0.016001281925134624,\n",
              " -0.021075792169818156,\n",
              " -0.014917530738722446,\n",
              " 0.01985179032586043,\n",
              " 0.015108780619387223,\n",
              " 0.03554707318698946,\n",
              " 0.027973556305981022,\n",
              " 0.030396062244981967,\n",
              " -0.03850508028196786,\n",
              " -0.02295004714706183,\n",
              " 0.027132056085997964,\n",
              " -0.01781178601083415,\n",
              " 0.007656390618577181,\n",
              " -0.011392147973317057,\n",
              " -5.1547957641119845e-05,\n",
              " 0.012310149821946628,\n",
              " 0.04006058266413591,\n",
              " -0.014790029886956706,\n",
              " -0.013935777998548726,\n",
              " -0.00020659026199509837,\n",
              " 0.023217796793728006,\n",
              " 0.02889155908593315,\n",
              " 0.008491516866992893,\n",
              " 0.0032114127444810227,\n",
              " -0.009887644814268239,\n",
              " 0.009320269143841257,\n",
              " -0.00670013888694691,\n",
              " 0.0204000412876177,\n",
              " -0.000938720690475376,\n",
              " 0.02300104637018106,\n",
              " 0.01337477723101165,\n",
              " -0.013553277305896618,\n",
              " 0.0265965549300205,\n",
              " -0.013170776613244511,\n",
              " -0.0006948764057774014,\n",
              " 0.040443084288110574,\n",
              " 0.03024306085033406,\n",
              " 0.030523562165425153,\n",
              " 0.010958647126223164,\n",
              " 0.0418200856640711,\n",
              " 0.013234526573466103,\n",
              " 0.0240975482936956,\n",
              " 0.008663642970310513,\n",
              " -0.010958647126223164,\n",
              " 0.025831553544716283,\n",
              " 0.012240024958835131,\n",
              " 0.010767397245558388,\n",
              " -0.007930516099455815,\n",
              " 0.002894255970603621,\n",
              " -0.003091881219819579,\n",
              " 0.03437406870350585,\n",
              " 0.02254204591152755,\n",
              " -0.002878318480548223,\n",
              " -0.002919756047824514,\n",
              " -0.003570007318465353,\n",
              " -0.03169656478626365,\n",
              " 0.017480285472623827,\n",
              " 0.016052283010898963,\n",
              " 0.0005267354316732063,\n",
              " -0.013578777848778789,\n",
              " 0.016447534440653434,\n",
              " 0.0054060112485551344,\n",
              " 0.004328634033710305,\n",
              " 0.016575034361096617,\n",
              " -0.013680778157662358,\n",
              " 0.0036082574342966916,\n",
              " 0.01707228423708955,\n",
              " 0.01945653889610596,\n",
              " -0.007203764597152299,\n",
              " -0.6617773632866815,\n",
              " -0.021012043140919118,\n",
              " 0.0012598619532819461,\n",
              " -0.011443148127758842,\n",
              " 0.017301784466416302,\n",
              " 0.010251020798250635,\n",
              " 0.0024591611649566135,\n",
              " 0.004287196233603375,\n",
              " -0.016090532428238383,\n",
              " 0.009588019721829988,\n",
              " -0.009804770145376935,\n",
              " 0.0077838910046816425,\n",
              " 0.0018439725587021604,\n",
              " -0.016371033743329478,\n",
              " -0.007216514868593383,\n",
              " -0.022580295328866976,\n",
              " -0.005539886071888222,\n",
              " -0.0069423893877147485,\n",
              " 0.020489291790721464,\n",
              " 0.0035508821441343646,\n",
              " 0.00786039123634432,\n",
              " 0.022159544287552888,\n",
              " -0.006795763827279298,\n",
              " 0.014280029273861412,\n",
              " 0.012144399552841465,\n",
              " -0.007426889923589149,\n",
              " -0.003589132259965703,\n",
              " -0.03478206993904013,\n",
              " -0.017556786169947783,\n",
              " 0.010582521336460959,\n",
              " -0.03633757232120818,\n",
              " 0.01852578817301914,\n",
              " 0.007382265137698545,\n",
              " 0.001635190880182913,\n",
              " 0.031951564627150014,\n",
              " -0.02414854937945994,\n",
              " -0.025806052070511558,\n",
              " 0.006642763363953944,\n",
              " 0.013145277001684896,\n",
              " 0.011111647589548518,\n",
              " 0.013604277460338403,\n",
              " -0.01652403327533228,\n",
              " 0.011149897938210496,\n",
              " 0.0019188789482270422,\n",
              " -0.0195075399818703,\n",
              " 0.02405929887635618,\n",
              " 0.01695753412242617,\n",
              " -0.01466252996651352,\n",
              " -0.0008199860286751703,\n",
              " -0.0069933890764952555,\n",
              " -0.004656947120475677,\n",
              " -0.012533275148383477,\n",
              " 0.02245279540842379,\n",
              " 0.022516546299967938,\n",
              " 0.0038409453478990365,\n",
              " -0.006783014021499491,\n",
              " 0.011577023882414484,\n",
              " -0.025385301029197473,\n",
              " -0.00041318052399019674,\n",
              " 0.00970914473938327,\n",
              " -0.008166391231672473,\n",
              " 0.012106150135502043,\n",
              " -0.029172060401024245,\n",
              " -0.019227038666779207,\n",
              " -0.011844774460403216,\n",
              " -0.00038011016227605416,\n",
              " -0.028509057461958486,\n",
              " 0.011889399711955097,\n",
              " 0.033609069180846746,\n",
              " 0.0019778478476965263,\n",
              " -0.007363139963367557,\n",
              " 0.018538537978798945,\n",
              " -0.01466252996651352,\n",
              " -0.013553277305896618,\n",
              " 0.007917766293676009,\n",
              " 0.003458444655246928,\n",
              " 0.01347677753989522,\n",
              " -0.01439477938852479,\n",
              " -0.0025021926907860185,\n",
              " -0.021726043440458996,\n",
              " 0.001898160164588897,\n",
              " -0.018780788013905505,\n",
              " -0.022669545831970738,\n",
              " 0.021216043758686257,\n",
              " 0.026341553226489022,\n",
              " -0.016281783240225715,\n",
              " -0.017684286090390966,\n",
              " 0.0028878808348830787,\n",
              " 0.011755523957299454,\n",
              " -0.005549448891884356,\n",
              " 0.018627788481902708,\n",
              " 0.03570007458163737,\n",
              " 0.011385773070427154,\n",
              " -0.011105272686658615,\n",
              " -0.006390950508851249,\n",
              " 0.011921274226404616,\n",
              " 0.013986778152990511,\n",
              " -0.0015555031970752838,\n",
              " 0.010008770763144074,\n",
              " -0.016103282234018194,\n",
              " 0.002167504468300104,\n",
              " 0.0067702637500584055,\n",
              " 0.0027300994272209354,\n",
              " 0.007363139963367557,\n",
              " 0.005450636034445738,\n",
              " -0.0022758796800735775,\n",
              " -0.015351031585816338,\n",
              " 0.016396533354889095,\n",
              " 0.009830269756936549,\n",
              " -0.010741896702676217,\n",
              " 0.01392302819276892,\n",
              " 0.0074077652149194375,\n",
              " -0.023919049150133185,\n",
              " 0.018589537201918173,\n",
              " 0.012590651137037721,\n",
              " -0.020119541835171718,\n",
              " 0.008695517484760032,\n",
              " 0.023880797870148653,\n",
              " -0.0029101934606590193,\n",
              " -0.010059770917585859,\n",
              " 0.010333896398464494,\n",
              " -0.016409283160668902,\n",
              " 0.008931393548299246,\n",
              " -0.035037069779926495,\n",
              " 0.011691773997077862,\n",
              " 0.028866059474373533,\n",
              " 0.011914899323514711,\n",
              " -0.006834013710279998,\n",
              " 0.019035789717436986,\n",
              " 0.012934901481027853,\n",
              " 0.006795763827279298,\n",
              " 0.00647382564340383,\n",
              " 0.022886296255517684,\n",
              " 0.007611765367025299,\n",
              " 0.01319627715612668,\n",
              " 0.014254528730979243,\n",
              " 0.012705401251701099,\n",
              " -0.00718463942282131,\n",
              " 0.01561878216380507,\n",
              " -0.026367054700693747,\n",
              " -0.02306479726172521,\n",
              " 0.015644281775364685,\n",
              " -0.0011411272914817407,\n",
              " 0.0028384746389944087,\n",
              " -0.0180285364343811,\n",
              " -0.025627552926949144,\n",
              " -0.02478605084432097,\n",
              " -0.03863257833976594,\n",
              " -0.030064561706771645,\n",
              " 0.014343779234083006,\n",
              " 0.02250379649418813,\n",
              " -0.0180285364343811,\n",
              " -0.014815530429838875,\n",
              " -0.018117786937484857,\n",
              " 0.0015547063342140459,\n",
              " -0.0005494464306721061,\n",
              " -0.006343137805854417,\n",
              " -0.008701892387649936,\n",
              " 0.0024384424977337876,\n",
              " -0.04220258728804576,\n",
              " 0.0070890144824889215,\n",
              " 0.003283131798976272,\n",
              " -0.022758796335074497,\n",
              " 0.004574071985923096,\n",
              " 0.015478531506259522,\n",
              " 0.017633286867271735,\n",
              " -0.00026854741174613946,\n",
              " 0.03781657586869738,\n",
              " 0.005527136266108415,\n",
              " -0.02799905778018575,\n",
              " 0.010614396782233033,\n",
              " -0.005654636652212877,\n",
              " -5.573156042219377e-05,\n",
              " 0.031212062853405415,\n",
              " 0.003216194154479089,\n",
              " 0.005141448122011355,\n",
              " -0.017378285163740258,\n",
              " -0.023039297650165592,\n",
              " 0.032461568034212976,\n",
              " 0.004940634955689167,\n",
              " -0.002078254198026981,\n",
              " -0.01925254014098393,\n",
              " -0.010359396010024108,\n",
              " -0.0158100329757924,\n",
              " 0.005029885458792929,\n",
              " -0.015873782004691438,\n",
              " 0.03144156494537728,\n",
              " -0.0062283876911910395,\n",
              " -0.015899281616251055,\n",
              " 0.006579013403732351,\n",
              " 0.002478286339287602,\n",
              " -0.0024894426521755724,\n",
              " 0.003799507780622746,\n",
              " 0.0076882655986879765,\n",
              " 0.001305283951279746,\n",
              " 0.014458529348746382,\n",
              " -0.019698790793857633,\n",
              " 0.00213881693963426,\n",
              " 0.015975782313575007,\n",
              " 0.01635828393754967,\n",
              " 0.0067702637500584055,\n",
              " 0.010837522108669883,\n",
              " 0.027106554611793236,\n",
              " -0.00946051887006425,\n",
              " 0.037026076734478656,\n",
              " -0.014305528885421028,\n",
              " 0.0026886616271140063,\n",
              " -0.02692805546823082,\n",
              " 0.05533511448395085,\n",
              " 0.010391271455796183,\n",
              " 0.002049566669361137,\n",
              " -0.00995777060870229,\n",
              " -0.04393659067642133,\n",
              " -0.0020240665921402445,\n",
              " -0.002145191842524164,\n",
              " 0.016906534899306942,\n",
              " -0.001993785337751924,\n",
              " -0.00670013888694691,\n",
              " -0.004233008627716639,\n",
              " -0.005335885919782361,\n",
              " 0.0008375173608683637,\n",
              " 0.007713765675908869,\n",
              " -0.012061524883950162,\n",
              " 0.006872264058941975,\n",
              " -0.04414059129418847,\n",
              " 0.029019059006376333,\n",
              " -0.00883576814230558,\n",
              " -0.004685634649141521,\n",
              " -0.006706513789836813,\n",
              " -0.0014606748867734948,\n",
              " 0.002207348309853919,\n",
              " -0.011162647743990303,\n",
              " 0.008988768605630934,\n",
              " 0.007726515947349954,\n",
              " 0.005651449200767925,\n",
              " 0.005444261131555834,\n",
              " 0.004656947120475677,\n",
              " -0.025461801726521426,\n",
              " 0.040545082734349036,\n",
              " -0.012864776617916357,\n",
              " 0.028458058238839255,\n",
              " 0.008313016792107924,\n",
              " 0.008746517639201817,\n",
              " -0.013553277305896618,\n",
              " 0.0014399561031353495,\n",
              " -0.008274766443445946,\n",
              " 0.022924547535502215,\n",
              " 0.0018806288323957037,\n",
              " -0.01646028424643324,\n",
              " 0.014407529194304597,\n",
              " -0.006355888077295501,\n",
              " 0.0056291365749919844,\n",
              " -0.01790103651393791,\n",
              " -0.003346881759197864,\n",
              " 0.00431588376226922,\n",
              " -0.0008518611252012858,\n",
              " -0.00496613503291006,\n",
              " 0.0005012354126599736,\n",
              " 0.016090532428238383,\n",
              " 0.03366006840396597,\n",
              " 0.0025308802194518626,\n",
              " 0.004950197775685301,\n",
              " 0.03327756677999131,\n",
              " 0.0023922235204594305,\n",
              " -0.003139693922816412,\n",
              " -0.00486413472402649,\n",
              " 0.0019395977318651875,\n",
              " 0.027055555388674008,\n",
              " -0.012539650982595936,\n",
              " -0.027463556624208286,\n",
              " -0.01364252780900038,\n",
              " -0.006381388154516394,\n",
              " 0.011475023573530915,\n",
              " -0.018691537510801742,\n",
              " 0.008670017873200417,\n",
              " 0.0077456406560196655,\n",
              " 0.03256356648045143,\n",
              " 0.0034839444996371816,\n",
              " -0.00653438815218047,\n",
              " 0.029401560630350997,\n",
              " -0.015606031426702707,\n",
              " -0.03391506824485234,\n",
              " -0.00040600864182373567,\n",
              " 0.03677107316830207,\n",
              " -0.021190544147126643,\n",
              " -0.013336526882349672,\n",
              " -0.011710898705747572,\n",
              " 0.018487536893034603,\n",
              " -0.009243768446517302,\n",
              " -0.0009777676109602928,\n",
              " 0.004621884223258651,\n",
              " 0.030574563251189492,\n",
              " -0.020030291332067955,\n",
              " -0.019392789867206925,\n",
              " -0.017722535507730387,\n",
              " -0.014241778925199436,\n",
              " 0.02120329395290645,\n",
              " -0.019698790793857633,\n",
              " -0.007280264828814976,\n",
              " -0.02055304268226561,\n",
              " -0.0009849394931267538,\n",
              " 0.009900395551370601,\n",
              " 0.006604513480953244,\n",
              " -0.010289271146912613,\n",
              " 0.01852578817301914,\n",
              " 0.005055385536013822,\n",
              " -0.020094040360966993,\n",
              " 0.00015369757280978835,\n",
              " 0.011373023264647345,\n",
              " -0.00403219592705573,\n",
              " 0.019928291023184386,\n",
              " -0.0005741495868241008,\n",
              " -0.014586030200512122,\n",
              " 0.004105508241612177,\n",
              " 0.0025531926123971644,\n",
              " 0.0017754410720671823,\n",
              " -0.017786286399274535,\n",
              " -0.015210780928270792,\n",
              " 0.018882788322789074,\n",
              " 0.0025531926123971644,\n",
              " -0.001329190186362843,\n",
              " -0.02603555229983831,\n",
              " -0.022886296255517684,\n",
              " -0.01702128501397032,\n",
              " 0.12331825236830345,\n",
              " 0.01150052318509053,\n",
              " 0.008497892701205352,\n",
              " 0.002124473175301338,\n",
              " 0.02993706178632846,\n",
              " 0.010659022033784913,\n",
              " -0.015491281312039331,\n",
              " -0.007375890234808642,\n",
              " 0.00840864219810159,\n",
              " 0.004229821176271687,\n",
              " -0.00437644627104586,\n",
              " 0.008523392312764966,\n",
              " -0.003576382221355257,\n",
              " -0.004229821176271687,\n",
              " -0.0116025234939741,\n",
              " -0.011220022801321991,\n",
              " -0.023485548303039293,\n",
              " 0.001899753890311373,\n",
              " -0.008472392158323181,\n",
              " -0.006107262673637759,\n",
              " -0.010455021416017774,\n",
              " 0.02045104237338204,\n",
              " -0.007917766293676009,\n",
              " 0.009913145357150408,\n",
              " -0.011551523339532315,\n",
              " -0.029478059465029842,\n",
              " 0.010754646508456025,\n",
              " 0.01981354090852101,\n",
              " 0.009658144584941485,\n",
              " 0.0061710126338593504,\n",
              " -0.0006434778781126573,\n",
              " 0.009594394624719891,\n",
              " 0.010761022342668484,\n",
              " 0.006508888074959578,\n",
              " 0.008007016796779771,\n",
              " 0.009639019876271773,\n",
              " -0.014930280544502253,\n",
              " 0.016039533205119156,\n",
              " 0.017442036055284403,\n",
              " -0.023115796484844436,\n",
              " -0.029860561089004506,\n",
              " -0.02509205177097168,\n",
              " -0.003506257125413122,\n",
              " -0.021279792787585294,\n",
              " 0.018615038676122898,\n",
              " 0.0072228897714832875,\n",
              " 0.0025229113580088444,\n",
              " 0.029860561089004506,\n",
              " -0.02346004869147968,\n",
              " -0.001239940032505039,\n",
              " 0.012393025422160486,\n",
              " 0.011118022492438422,\n",
              " -0.015134281162269392,\n",
              " -0.019635039902313484,\n",
              " -0.03835207888731995,\n",
              " 0.029503560939234567,\n",
              " 0.013833778620987712,\n",
              " 0.044370091523515225,\n",
              " 0.015606031426702707,\n",
              " 0.010531521182019174,\n",
              " -0.022567545523087165,\n",
              " -0.02149654321113224,\n",
              " -0.013413027579673626,\n",
              " -0.006371825334520261,\n",
              " -0.006572638500842448,\n",
              " -0.004711134726362413,\n",
              " -0.023727798338145853,\n",
              " -0.02014504144673133,\n",
              " -0.00865726806742061,\n",
              " -0.01731453613484122,\n",
              " -0.012992276538359541,\n",
              " -0.0030504436525432884,\n",
              " -0.006661888538284933,\n",
              " 0.010098020334925281,\n",
              " 0.030600062862749106,\n",
              " -0.013425777385453435,\n",
              " 0.00747151517514103,\n",
              " -0.014356529039862813,\n",
              " -0.011691773997077862,\n",
              " -0.013884778775429497,\n",
              " -0.022491046688408324,\n",
              " -0.01185114936329312,\n",
              " -0.0356235720216683,\n",
              " -0.03197706423870963,\n",
              " -0.008663642970310513,\n",
              " 0.028917058697492764,\n",
              " 0.004982072755796096,\n",
              " -0.022491046688408324,\n",
              " -0.010576146433571056,\n",
              " 0.04062158156902788,\n",
              " 0.0015037061797722611,\n",
              " 0.01114352303532059,\n",
              " 0.003719820097515117,\n",
              " -0.004284008782158424,\n",
              " 0.005523948814663463,\n",
              " -0.0022663170929080835,\n",
              " 0.0018312225200917142,\n",
              " -0.004736634803583306,\n",
              " -0.01364252780900038,\n",
              " 0.0223125456822008,\n",
              " 0.013948528735651089,\n",
              " -0.03587857186255467,\n",
              " -0.01642203296644871,\n",
              " -0.013425777385453435,\n",
              " -0.008912267908306978,\n",
              " 0.003898320405230725,\n",
              " 0.0032895067018661756,\n",
              " 0.015504032049141693,\n",
              " -0.024977301656308303,\n",
              " -0.0027460369172763333,\n",
              " 0.017620535198846817,\n",
              " -0.014343779234083006,\n",
              " 0.010761022342668484,\n",
              " 0.01767153628461116,\n",
              " -0.013540527500116811,\n",
              " 0.03322656755687208,\n",
              " 0.013387527036791457,\n",
              " 0.01991554121740458,\n",
              " -0.006757513944278598,\n",
              " 0.010525146279129271,\n",
              " 0.021318044067569826,\n",
              " -0.01996654044052381,\n",
              " 0.01646028424643324,\n",
              " -0.009779269602494764,\n",
              " -0.021483793405352433,\n",
              " 0.015172530579608814,\n",
              " -0.01642203296644871,\n",
              " -0.032614565703570665,\n",
              " -0.02034904206449847,\n",
              " -0.013897528581209304,\n",
              " -0.011111647589548518,\n",
              " 0.00022232857999093168,\n",
              " 0.0039971330298387035,\n",
              " -0.010467771221797583,\n",
              " -0.016014033593559542,\n",
              " 0.008058016019899,\n",
              " -0.0018870038517009267,\n",
              " -0.0002508169220452963,\n",
              " -0.014726279926735114,\n",
              " -0.021445543988013013,\n",
              " -0.011283772761543583,\n",
              " 0.0026759118213341986,\n",
              " -0.013451276997013048,\n",
              " -0.018844538905449654,\n",
              " -0.0033436943077529125,\n",
              " -0.024798800650100778,\n",
              " 0.0021308480781912415,\n",
              " -0.017034034819750125,\n",
              " 0.014254528730979243,\n",
              " 0.007152764442710514,\n",
              " -0.011914899323514711,\n",
              " 0.007701015870129062,\n",
              " -7.645034769831773e-05,\n",
              " 0.030855062703635475,\n",
              " -0.0120487741468478,\n",
              " -0.029044558617935947,\n",
              " -0.02459480003233364,\n",
              " 0.024620299643893256,\n",
              " 0.020655042991149182,\n",
              " 0.04498209337681665,\n",
              " -0.007337639886146665,\n",
              " 0.009741020185155342,\n",
              " 0.010735521799786313,\n",
              " 0.007579890386914504,\n",
              " 0.0030376936139328422,\n",
              " -0.030498062553865536,\n",
              " 0.0009450956515729393,\n",
              " -0.010697271451124335,\n",
              " -0.026571053455815775,\n",
              " -0.02166229441155996,\n",
              " 0.030447061468101198,\n",
              " 0.008689142581870129,\n",
              " 0.012877526423696163,\n",
              " 0.009224643737847591,\n",
              " 0.014241778925199436,\n",
              " 0.00653438815218047,\n",
              " 0.0051159480447904625,\n",
              " 0.007701015870129062,\n",
              " -0.009339393852510968,\n",
              " -0.015644281775364685,\n",
              " -0.019520289787650108,\n",
              " -0.018640538287682515,\n",
              " -0.008937768451189149,\n",
              " -0.008778393084973891,\n",
              " -0.0006821263671669552,\n",
              " -0.02639255431225336,\n",
              " 0.037255576963805416,\n",
              " 0.009020643120080453,\n",
              " -0.0032640066246452833,\n",
              " -0.007994266059677407,\n",
              " 0.010251020798250635,\n",
              " 0.004166071216050095,\n",
              " 0.004095945887277321,\n",
              " 0.0002773130778427361,\n",
              " -0.021675044217339765,\n",
              " -0.012259149667504844,\n",
              " -0.01991554121740458,\n",
              " -0.010321145661362132,\n",
              " -0.016077782622458577,\n",
              " 0.010238270992470828,\n",
              " 0.03218106485647677,\n",
              " 0.005979762287533296,\n",
              " 0.0006904936018329329,\n",
              " 0.005412386151445038,\n",
              " 0.006744763672837513,\n",
              " 0.021534794491116775,\n",
              " -0.012157149358621274,\n",
              " 0.0070890144824889215,\n",
              " -0.0065853883066222555,\n",
              " -0.009243768446517302,\n",
              " -0.01346402773411541,\n",
              " -0.005683324180878721,\n",
              " 0.006234762594080943,\n",
              " -0.042100585116517084,\n",
              " 0.01150052318509053,\n",
              " 0.005788511941207242,\n",
              " -0.0004928681779939959,\n",
              " -0.0004653759436200086,\n",
              " 0.018232537052148237,\n",
              " -0.012284650210387013,\n",
              " 0.011162647743990303,\n",
              " -0.01207427468972997,\n",
              " -0.0010160177267916314,\n",
              " -0.010289271146912613,\n",
              " 0.029707559694356594,\n",
              " 0.021114043449802687,\n",
              " 0.014139778616315867,\n",
              " -0.02932505993302704,\n",
              " 0.02754005545888713,\n",
              " 0.01294765128680766,\n",
              " 0.0024272861848458173,\n",
              " 0.030166562015655214,\n",
              " 0.007592640658355588,\n",
              " 0.011934024032184423,\n",
              " 0.00832576659788773,\n",
              " -0.02853455893616321,\n",
              " 0.04442109074663446,\n",
              " 0.003071162552596753,\n",
              " -0.013693527963442165,\n",
              " 0.023970048373252416,\n",
              " 0.03077856200631152,\n",
              " -0.007344014789036568,\n",
              " -0.006955139193494556,\n",
              " -0.019724290405417247,\n",
              " -0.03128856355072937,\n",
              " 0.0365160733274157,\n",
              " -0.03327756677999131,\n",
              " -0.016485783857992854,\n",
              " -0.01820703744058862,\n",
              " -0.019392789867206925,\n",
              " -0.018972038825892837,\n",
              " -0.007414140117809342,\n",
              " -0.029299560321467428,\n",
              " 0.015108780619387223,\n",
              " 0.013757277923663758,\n",
              " 0.006719263595616621,\n",
              " -0.009836644659826454,\n",
              " -0.0042266337248267356,\n",
              " 0.005144635573456307,\n",
              " 0.008453267449653471,\n",
              " -0.013910278386989113,\n",
              " 0.008070766757001363,\n",
              " -0.03513907195145518,\n",
              " -0.029274058847262703,\n",
              " 0.030753062394751906,\n",
              " 0.010136270683587259,\n",
              " 0.0013666434393329436,\n",
              " -0.007809391081902535,\n",
              " 0.015453031894699909,\n",
              " 0.021126793255582494,\n",
              " -0.024518299335009687,\n",
              " -0.01770978570195058,\n",
              " -0.015338280848713975,\n",
              " 0.010423145970245701,\n",
              " 0.009307519338061449,\n",
              " -0.015134281162269392,\n",
              " 0.006253887768411932,\n",
              " 0.0005861027625733091,\n",
              " 0.0026679429598911804,\n",
              " 0.0021818482326330267,\n",
              " 0.007726515947349954,\n",
              " 0.02280979742083884,\n",
              " -0.003173162628649684,\n",
              " -0.026469053146932205,\n",
              " 0.00863176752453844,\n",
              " -0.0038090703677882403,\n",
              " 0.012488650828154152,\n",
              " 0.0033755692878637083,\n",
              " -0.017327285940621027,\n",
              " -0.02175154491466372,\n",
              " -0.026520054232696544,\n",
              " 0.0026488180183908304,\n",
              " -0.019686040988077826,\n",
              " 0.028968059783257106,\n",
              " 0.0030520373782657647,\n",
              " 0.0052434479652336465,\n",
              " -0.00848514196410299,\n",
              " 0.03802057648646452,\n",
              " -0.02599730288249889,\n",
              " 0.008051641117009097,\n",
              " 0.022019294561329898,\n",
              " 0.006021199621978948,\n",
              " -0.0011913305830622875,\n",
              " 0.014088778461874082,\n",
              " 0.005351823642668397,\n",
              " -0.014152528422095674,\n",
              " 0.016371033743329478,\n",
              " -0.0236512976408219,\n",
              " -0.028024557391745364,\n",
              " -0.01150052318509053,\n",
              " -0.008593517175876463,\n",
              " 0.014088778461874082,\n",
              " -0.0013833777922495796,\n",
              " -0.01935453858722239,\n",
              " 0.014930280544502253,\n",
              " 0.017187034351752926,\n",
              " 0.016077782622458577,\n",
              " 0.004924697698464408,\n",
              " -0.027132056085997964,\n",
              " 0.0064897633662898664,\n",
              " 0.021126793255582494,\n",
              " -0.001570643824269444,\n",
              " 0.017824535816613956,\n",
              " -0.02514305099409091,\n",
              " 0.030574563251189492,\n",
              " 0.008115392008553244,\n",
              " 0.0015323937084381054,\n",
              " 0.018270786469487658,\n",
              " 0.008561642661426944,\n",
              " -0.004857759821136586,\n",
              " 0.023090296873284823,\n",
              " -0.005268948042454539,\n",
              " 0.011366648361757442,\n",
              " -0.022860796643958067,\n",
              " -0.017238035437517264,\n",
              " -0.01575903189002806,\n",
              " -0.0012096586617013994,\n",
              " 0.006572638500842448,\n",
              " 0.02455655061499422,\n",
              " 0.015504032049141693,\n",
              " -0.003216194154479089,\n",
              " 0.018474787087254797,\n",
              " 0.02152204468533697,\n",
              " -0.02284804683817826,\n",
              " -0.005421948505779893,\n",
              " -0.02025979156139471,\n",
              " -0.01099689747488514,\n",
              " 0.017378285163740258,\n",
              " -0.0232050469879482,\n",
              " -0.013056026498581133,\n",
              " 0.012533275148383477,\n",
              " 0.03978007948639971,\n",
              " 0.007191014791372491,\n",
              " 0.01875528840234589,\n",
              " -0.022172295955977805,\n",
              " 0.007133639734040803,\n",
              " -0.01347677753989522,\n",
              " 0.007522515329582815,\n",
              " -0.01132202311020556,\n",
              " -0.003971632952617811,\n",
              " 0.029121059315259903,\n",
              " 0.008842143045195483,\n",
              " 0.01770978570195058,\n",
              " 0.017238035437517264,\n",
              " -0.010958647126223164,\n",
              " 0.0035795699056308476,\n",
              " 0.004535821637261119,\n",
              " -0.016638783389995655,\n",
              " 0.0005394854702836525,\n",
              " -0.020871793414696128,\n",
              " -0.018245286857928044,\n",
              " 0.019992040052083423,\n",
              " -0.02418679879679936,\n",
              " 0.01974979001697686,\n",
              " 0.0223125456822008,\n",
              " 0.013336526882349672,\n",
              " -0.00823014212321662,\n",
              " 0.01237389978216822,\n",
              " -0.00596382456464726,\n",
              " -0.005457010937335641,\n",
              " -0.00293250608643496,\n",
              " -0.03141606533381766,\n",
              " -0.0062953255685188605,\n",
              " 0.024518299335009687,\n",
              " -0.0049916351101309524,\n",
              " -0.04561959484167768,\n",
              " 0.0016989409568198245,\n",
              " 0.0024352550462888355,\n",
              " 0.005820386921318039,\n",
              " -0.005829949275652894,\n",
              " -0.01371902757500178,\n",
              " 0.02404654907057637,\n",
              " -0.015465781700479716,\n",
              " 0.00696151409638446,\n",
              " -0.017684286090390966,\n",
              " -0.025755052847392327,\n",
              " 0.00018308240013496056,\n",
              " -0.019341788781442583,\n",
              " 0.041896584498749945,\n",
              " 0.026022802494058504,\n",
              " -0.003541319789799509,\n",
              " -0.007191014791372491,\n",
              " -0.000498446334437981,\n",
              " 0.00012251977494300083,\n",
              " -0.005335885919782361,\n",
              " -0.020731541825828023,\n",
              " -0.04865410077133493,\n",
              " -0.005472948660221678,\n",
              " -0.023370798188375917,\n",
              " -0.013183527350346873,\n",
              " 0.0079815162538976,\n",
              " 0.0003695515256378422,\n",
              " 0.009817519951156742,\n",
              " -0.04658859498210392,\n",
              " -0.004013070752724741,\n",
              " -0.011379398167537249,\n",
              " -0.007586265289804407,\n",
              " -0.016600533972656234,\n",
              " 0.03332856972840076,\n",
              " 0.017939285931277336,\n",
              " -0.01656228455531681,\n",
              " -0.0012056743473952097,\n",
              " -0.014777280081176899,\n",
              " -0.01985179032586043,\n",
              " 0.00895689315985886,\n",
              " -0.026418053923812974,\n",
              " 0.009148143971846191,\n",
              " -0.005361385997003253,\n",
              " -0.01340027777389382,\n",
              " 0.017786286399274535,\n",
              " -0.03541957140390116,\n",
              " -0.017085034042869356,\n",
              " 0.005217948353674032,\n",
              " -0.00509044796756957,\n",
              " -0.01297315182968983,\n",
              " 4.81114247063927e-05,\n",
              " 0.2049184249693547,\n",
              " -0.030498062553865536,\n",
              " -0.01097777276621543,\n",
              " 0.01306877630436094,\n",
              " -0.005664199006547732,\n",
              " 0.003071162552596753,\n",
              " 0.026265054391810178,\n",
              " 0.0013108619913084116,\n",
              " 0.00910351872029431,\n",
              " -0.008918642811196883,\n",
              " -0.01457327946340976,\n",
              " -0.0010662209019568587,\n",
              " -0.006980639270715449,\n",
              " 0.01790103651393791,\n",
              " 0.012310149821946628,\n",
              " -0.02784605638553784,\n",
              " -0.030753062394751906,\n",
              " -0.04286558836446641,\n",
              " -0.0027316931529434113,\n",
              " -0.017837285622393766,\n",
              " 0.012992276538359541,\n",
              " -0.003652882453017934,\n",
              " -0.0011546741929534248,\n",
              " 0.004494384302815467,\n",
              " 0.001898160164588897,\n",
              " -0.027922557082861794,\n",
              " 9.144159220982554e-05,\n",
              " 0.00925014428072976,\n",
              " 0.0075033901552518266,\n",
              " -0.006416450586072141,\n",
              " -0.044370091523515225,\n",
              " 0.0034488820680814336,\n",
              " -0.023766047755485277,\n",
              " 0.009868520105598527,\n",
              " -0.002754005545888713,\n",
              " 0.012227275153055325,\n",
              " 0.02754005545888713,\n",
              " 0.003315006779087068,\n",
              " 0.000490477589410282,\n",
              " 0.012826526269254379,\n",
              " 0.002237629564242239,\n",
              " -0.017187034351752926,\n",
              " -0.0011873461523407784,\n",
              " 0.000624751251627607,\n",
              " -0.016842784007762793,\n",
              " 0.0095306446644983,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Insertar los embeddings en un √≠ndice de Pinecone** üì•"
      ],
      "metadata": {
        "id": "pP3FqBg7vqxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a transformar todos nuestros chunks en vectores num√©ricos e insertarlos en el √≠ndice de Pinecone"
      ],
      "metadata": {
        "id": "wqfiRUixwMF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pinecone\n",
        "from langchain.vectorstores import  Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "PHP9eBwwwLw6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el √≠ndice que hemos creado previamente (index)\n",
        "# Los pasos para crear un √≠ndice se vieron previamente en este mismo cuaderno\n",
        "# Comprobamos que est√° creado\n",
        "index.describe_index_stats()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKH5742KvEgn",
        "outputId": "bd5d4c71-9939-4de3-fd98-c71e843f52f5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.00605,\n",
              " 'namespaces': {'': {'vector_count': 605}},\n",
              " 'total_vector_count': 605}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subimos los vectores a Pinecone con Langchain.\n",
        "Hay que tener en cuenta los objetos que ya hab√≠amos creado:\n",
        "- **Chunks**, con todos nuestros fragmentos.\n",
        "- **Embedding**, donde ya ten√≠amos nuestro objeto embedding:\n",
        "\n",
        "\n",
        "```\n",
        "      from langchain.embeddings import OpenAIEmbeddings\n",
        "      embedding = OpenAIEmbeddings()\n",
        "```\n",
        " - **El √≠ndice**, ya creado en Pinecone.\n",
        "  ****Un apunte, para vaciar el √≠ndice si ejecutas por error varias veces una celda:\n",
        "\n",
        "\n",
        "```\n",
        "# Vaciar el √≠ndice\n",
        "          index.delete(delete_all=True)```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qsy8jh1b2Vtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hPzNdr-ArDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos los vectores:"
      ],
      "metadata": {
        "id": "fumq6UvTALD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos los vectores (si vamos a la app veremos que nuestro √≠ndice, despu√©s de ejecutar esta celda, tiene 4 vectores.)\n",
        "vector_store = Pinecone.from_documents(chunks, embedding,index_name='langchain-pinecone' )\n",
        "\n",
        "#  Alternativa: docsearch = Pinecone.from_texts([page.page_content for page in chunks], embedding, index_name='langchain-pinecone')\n"
      ],
      "metadata": {
        "id": "Fr0NAnVw2Uqi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Similarity search:  preguntas üîç**\n",
        "\n",
        "Vamos a ver c√≥mo realizar preguntas y hacer b√∫squedas por similaridad. El proceso es el siguiente:\n",
        " - El usuario define una consulta (query)\n",
        " - La query se codifica (embedding) en un vector\n",
        " - El texto que se corresponde al vector m√°s similar es la respuesta a la consulta.\n"
      ],
      "metadata": {
        "id": "kycjlHXsAUO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teniendo en cuenta que el discurso de llama 'we shall fight in the beaches', preguntamos\n",
        "query = 'where should we fight?'\n",
        "resultado = vector_store.similarity_search(query)\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX6Wvx822Oze",
        "outputId": "077a53fc-9bcd-4280-ef8f-28d2a6a6d6db"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and'), Document(page_content='shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and'), Document(page_content='shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and'), Document(page_content='shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vemos, nos ha devuelto los fragmentos que contienen ese texto. Tambi√©n podemos iterar sobre los fragmentos (chunks), e imprimir solo su texto:"
      ],
      "metadata": {
        "id": "POXp_lDzBubp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for r in resultado:\n",
        "  print(r.page_content)\n",
        "  print('--'*50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_WgCaRIB4an",
        "outputId": "fc332c52-d69b-40d8-f152-496049bc3d92"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and\n",
            "----------------------------------------------------------------------------------------------------\n",
            "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and\n",
            "----------------------------------------------------------------------------------------------------\n",
            "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and\n",
            "----------------------------------------------------------------------------------------------------\n",
            "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque ya tenemos respuesta, debemos d√°rsela al usuario en un formato de lenguaje natural, m√°s amigable. Para eso, tomamos los fragmentos (chunks) m√°s relevantes y se los trasladamos al modelo de lenguaje para recibir la respuesta final."
      ],
      "metadata": {
        "id": "46Nrl-ynCNqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model= 'gpt-3.5-turbo', temperature=1)"
      ],
      "metadata": {
        "id": "gwUjovxuCM5a"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# El retriever se encargar√° de devolvernos los fragmentos en base a la similaridad\n",
        "retriever = vector_store.as_retriever(search_type = 'similarity', search_kwargs= {'k':3}) # Devolver√° los tres chunks m√°s similares\n",
        "\n",
        "# Creamos una cadena para responder, a la que le vamos a pasar el retriever\n",
        "chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever) # \"Stuff\" usa todo el texto de los documentos en el prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "gYoL9oeiDJtg"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya tenemos todo listo, vamos a hacer preguntas sobre el contenido del documento."
      ],
      "metadata": {
        "id": "Kf1BxLbnwVBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Where should we fight?\"\n",
        "answer = chain.run(query)\n"
      ],
      "metadata": {
        "id": "ae1X-PF3wOWI"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬°Listo! tenemos una respuesta en lenguaje natural, sencilla de leer, user-friendly."
      ],
      "metadata": {
        "id": "RkJRgSB4w7dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD8dosmcw2bY",
        "outputId": "d0f27d37-0fb5-42cf-e632-b05a53b04f40"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We should fight on the beaches, on the landing grounds, and in the fields.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos a preguntar otra cosa..."
      ],
      "metadata": {
        "id": "o71OrokLxC7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was the king of Belgium at that time?\"\n",
        "answer = chain.run(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2HISB-oxLBW",
        "outputId": "091f6287-84a0-4ea8-9cb3-bcc451b367c0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "King Leopold was the king of Belgium at that time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"C√≥mo se llamaba era el rey de Belgica en aquel momento?\"\n",
        "answer = chain.run(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTfH8XLvxsH4",
        "outputId": "ce222eb3-e695-4a08-f0cd-beaac3e6572f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El rey de B√©lgica en ese momento era Leopoldo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What about French troops?\"\n",
        "answer = chain.run(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuUTtFbGyV3A",
        "outputId": "5d9b3255-d1e2-4d39-958e-5ec46b19ae79"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The context suggests that there are French troops currently holding something, but it does not provide specific details about what they are holding. Without more information, it is difficult to provide a precise answer to your question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ú®‚ú® Si has llegado hasta aqu√≠, enhorabuena, puedes dejar cualquier feedback o correcci√≥n en ireneccprogramacion@gmail.com‚ú®‚ú®\n"
      ],
      "metadata": {
        "id": "E9srZ0IM13r3"
      }
    }
  ]
}